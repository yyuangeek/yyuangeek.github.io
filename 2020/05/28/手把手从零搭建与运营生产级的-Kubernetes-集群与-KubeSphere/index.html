<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="YYUAN">
  <meta name="keywords" content="">
  <title>手把手从零搭建与运营生产级的 Kubernetes 集群与 KubeSphere - YuanTech</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>YuanTech</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-05-28 22:11">
      May 28, 2020 pm
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      6.1k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      82
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p><img src="D:%5CBlog%5Cyyuangeek.github.io%5Csource_posts%5C%E6%89%8B%E6%8A%8A%E6%89%8B%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E4%B8%8E%E8%BF%90%E8%90%A5%E7%94%9F%E4%BA%A7%E7%BA%A7%E7%9A%84-Kubernetes-%E9%9B%86%E7%BE%A4%E4%B8%8E-KubeSphere%5C20200327191533.png" srcset="/img/loading.gif" alt="20200327191533"></p>
<p>本文将从零开始，在干净的机器上安装 Docker、Kubernetes (使用 kubeadm)、Calico、Helm、NFS StorageClass，通过手把手的教程演示如何搭建一个高可用生产级的 Kubernetes，并在 Kubernetes 集群之上安装开源的 <a href="https://github.com/kubesphere/kubesphere" target="_blank" rel="noopener">KubeSphere 容器平台</a>可视化运营集群环境。</p>
<h2 id="一、准备环境"><a href="#一、准备环境" class="headerlink" title="一、准备环境"></a>一、准备环境</h2><p>开始部署之前，请先确定当前满足如下条件，本次集群搭建，所有机器处于同一内网网段，并且可以互相通信。</p>
<p>⚠️⚠️⚠️：请详细阅读第一部分，后面的所有操作都是基于这个环境的，为了避免后面部署集群出现各种各样的问题，强烈建议你完全满足第一部分的环境要求</p>
<blockquote>
<ul>
<li>两台以上主机</li>
<li>每台主机的主机名、Mac 地址、UUID 不相同</li>
<li>CentOS 7（本文用 7.6/7.7）</li>
<li>每台机器最好有 2G 内存或以上</li>
<li>Control-plane/Master至少 2U 或以上</li>
<li>各个主机之间网络相通</li>
<li>禁用交换分区</li>
<li>禁用 SELINUX</li>
<li>关闭防火墙（我自己的选择，你也可以设置相关防火墙规则）</li>
<li>Control-plane/Master和Worker节点分别开放如下端口</li>
</ul>
</blockquote>
<p>Master节点</p>
<table>
<thead>
<tr>
<th align="center">协议</th>
<th align="center">方向</th>
<th align="center">端口范围</th>
<th align="center">作用</th>
<th align="center">使用者</th>
</tr>
</thead>
<tbody><tr>
<td align="center">TCP</td>
<td align="center">入站</td>
<td align="center">6443*</td>
<td align="center">Kubernetes API 服务器</td>
<td align="center">所有组件</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">入站</td>
<td align="center">2379-2380</td>
<td align="center">etcd server client API</td>
<td align="center">kube-apiserver, etcd</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">入站</td>
<td align="center">10250</td>
<td align="center">Kubelet API</td>
<td align="center">kubelet 自身、控制平面组件</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">入站</td>
<td align="center">10251</td>
<td align="center">kube-scheduler</td>
<td align="center">kube-scheduler 自身</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">入站</td>
<td align="center">10252</td>
<td align="center">kube-controller-manager</td>
<td align="center">kube-controller-manager 自身</td>
</tr>
</tbody></table>
<p>Worker节点</p>
<table>
<thead>
<tr>
<th align="center">协议</th>
<th align="center">方向</th>
<th align="center">端口范围</th>
<th align="center">作用</th>
<th align="center">使用者</th>
</tr>
</thead>
<tbody><tr>
<td align="center">TCP</td>
<td align="center">入站</td>
<td align="center">10250</td>
<td align="center">Kubelet API</td>
<td align="center">kubelet 自身、控制平面组件</td>
</tr>
<tr>
<td align="center">TCP</td>
<td align="center">入站</td>
<td align="center">30000-32767</td>
<td align="center">NodePort 服务**</td>
<td align="center">所有组件</td>
</tr>
</tbody></table>
<p>其他相关操作如下：</p>
<blockquote>
<p>友情提示😊，如果集群过多，可以了解下 ansible，批量管理你的多台机器，方便实用的工具。</p>
</blockquote>
<p>先进行防火墙、交换分区设置</p>
<pre><code class="hljs bash"><span class="hljs-comment"># 为了方便本操作关闭了防火墙，也建议你这样操作</span>
systemctl stop firewalld
systemctl <span class="hljs-built_in">disable</span> firewalld

<span class="hljs-comment"># 关闭 SeLinux</span>
setenforce 0
sed -i <span class="hljs-string">"s/SELINUX=enforcing/SELINUX=disabled/g"</span> /etc/selinux/config

<span class="hljs-comment"># 关闭 swap</span>
swapoff -a
yes | cp /etc/fstab /etc/fstab_bak
cat /etc/fstab_bak |grep -v swap &gt; /etc/fstab</code></pre>

<p>更换CentOS YUM源为阿里云yum源</p>
<pre><code class="hljs bash"><span class="hljs-comment"># 安装wget</span>
yum install wget -y
<span class="hljs-comment"># 备份</span>
mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
<span class="hljs-comment"># 获取阿里云yum源</span>
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
<span class="hljs-comment"># 获取阿里云epel源</span>
wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
<span class="hljs-comment"># 清理缓存并创建新的缓存</span>
yum clean all &amp;&amp; yum makecache
<span class="hljs-comment"># 系统更新</span>
yum update -y</code></pre>

<p>进行时间同步，并确认时间同步成功</p>
<pre><code class="hljs shell">timedatectl
timedatectl set-ntp true</code></pre>

<blockquote>
<p>⚠️⚠️⚠️以下操作请严格按照声明的版本进行部署，否则将碰到乱七八糟的问题</p>
</blockquote>
<h1 id="二、安装-Docker"><a href="#二、安装-Docker" class="headerlink" title="二、安装 Docker"></a>二、安装 Docker</h1><h2 id="2-1、安装-Docker"><a href="#2-1、安装-Docker" class="headerlink" title="2.1、安装 Docker"></a>2.1、安装 Docker</h2><p>您需要在每台机器上安装 Docker，我这里安装的是 docker-ce-19.03.4</p>
<pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 安装 Docker CE</span>
<span class="hljs-meta">#</span><span class="bash"> 设置仓库</span>
<span class="hljs-meta">#</span><span class="bash"> 安装所需包</span>
yum install -y yum-utils \
    device-mapper-persistent-data \
    lvm2

<span class="hljs-meta">#</span><span class="bash"> 新增 Docker 仓库,速度慢的可以换阿里云的源。</span>
yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
<span class="hljs-meta">#</span><span class="bash"> 阿里云源地址</span>
<span class="hljs-meta">#</span><span class="bash"> http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span>

<span class="hljs-meta">#</span><span class="bash"> 安装 Docker CE.</span>
yum install -y containerd.io-1.2.10 \
    docker-ce-19.03.4 \
    docker-ce-cli-19.03.4

<span class="hljs-meta">#</span><span class="bash"> 启动 Docker 并添加开机启动</span>
systemctl start docker
systemctl enable docker</code></pre>



<h2 id="2-2、修改-Cgroup-Driver"><a href="#2-2、修改-Cgroup-Driver" class="headerlink" title="2.2、修改 Cgroup Driver"></a>2.2、修改 Cgroup Driver</h2><p>需要将Docker 的 Cgroup Driver 修改为 systemd，不然在为Kubernetes 集群添加节点时会报如下错误：</p>
<pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 执行 kubeadm join 的 WARNING 信息</span>
[WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/</code></pre>

<p>目前 Docker 的 Cgroup Driver 看起来应该是这样的：</p>
<pre><code class="hljs java">$ docker info|grep <span class="hljs-string">"Cgroup Driver"</span>
  Cgroup Driver: cgroupfs</code></pre>

<p>需要将这个值修改为 systemd ，同时我将registry替换成国内的一些仓库地址，以免直接在官方仓库拉取镜像会很慢，操作如下。</p>
<blockquote>
<p>⚠️⚠️⚠️：注意缩进，直接复制的缩进可能有问题，请确保缩进为正确的 Json 格式；如果 Docker 重启后查看状态不正常，大概率是此文件缩进有问题，Json格式的缩进自己了解一下。</p>
</blockquote>
<pre><code class="hljs java"># Setup daemon.
cat &gt; /etc/docker/daemon.json &lt;&lt;EOF
&#123;
    <span class="hljs-string">"exec-opts"</span>: [<span class="hljs-string">"native.cgroupdriver=systemd"</span>],
    <span class="hljs-string">"log-driver"</span>: <span class="hljs-string">"json-file"</span>,
    <span class="hljs-string">"log-opts"</span>: &#123;
    <span class="hljs-string">"max-size"</span>: <span class="hljs-string">"100m"</span>
    &#125;,
    <span class="hljs-string">"storage-driver"</span>: <span class="hljs-string">"overlay2"</span>,
    <span class="hljs-string">"registry-mirrors"</span>:[
        <span class="hljs-string">"https://kfwkfulq.mirror.aliyuncs.com"</span>,
        <span class="hljs-string">"https://2lqq34jg.mirror.aliyuncs.com"</span>,
        <span class="hljs-string">"https://pee6w651.mirror.aliyuncs.com"</span>,
        <span class="hljs-string">"http://hub-mirror.c.163.com"</span>,
        <span class="hljs-string">"https://docker.mirrors.ustc.edu.cn"</span>,
        <span class="hljs-string">"https://registry.docker-cn.com"</span>
    ]
&#125;
EOF

mkdir -p /etc/systemd/system/docker.service.d

# Restart docker.
systemctl daemon-reload
systemctl restart docker</code></pre>



<h1 id="三、安装-kubeadm、kubelet-和-kubectl"><a href="#三、安装-kubeadm、kubelet-和-kubectl" class="headerlink" title="三、安装 kubeadm、kubelet 和 kubectl"></a>三、安装 kubeadm、kubelet 和 kubectl</h1><h2 id="3-1、安装准备"><a href="#3-1、安装准备" class="headerlink" title="3.1、安装准备"></a>3.1、安装准备</h2><p>需要在每台机器上安装以下的软件包：</p>
<ul>
<li>kubeadm：用来初始化集群的指令。</li>
<li>kubelet：在集群中的每个节点上用来启动 pod 和容器等。</li>
<li>kubectl：用来与集群通信的命令行工具（Worker 节点可以不装，但是我装了，不影响什么）。</li>
</ul>
<pre><code class="hljs java"># 配置K8S的yum源
# 这部分用是阿里云的源，如果可以访问Google，则建议用官方的源
cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http:<span class="hljs-comment">//mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span>
enabled=<span class="hljs-number">1</span>
gpgcheck=<span class="hljs-number">1</span>
repo_gpgcheck=<span class="hljs-number">1</span>
gpgkey=http:<span class="hljs-comment">//mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span>
EOF

# 官方源配置如下
cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https:<span class="hljs-comment">//packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</span>
enabled=<span class="hljs-number">1</span>
gpgcheck=<span class="hljs-number">1</span>
repo_gpgcheck=<span class="hljs-number">1</span>
gpgkey=https:<span class="hljs-comment">//packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span>
EOF</code></pre>



<h2 id="3-2、开始安装"><a href="#3-2、开始安装" class="headerlink" title="3.2、开始安装"></a>3.2、开始安装</h2><p>安装指定版本 kubelet、 kubeadm 、kubectl， 我这里选择当前较新的稳定版 Kubernetes 1.17.3，如果选择的版本不一样，在执行集群初始化的时候，注意 –kubernetes-version 的值。</p>
<pre><code class="hljs java"># 增加配置
cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward=<span class="hljs-number">1</span>
net.bridge.bridge-nf-call-ip6tables = <span class="hljs-number">1</span>
net.bridge.bridge-nf-call-iptables = <span class="hljs-number">1</span>
EOF
# 加载
sysctl --system

# 安装
yum install -y kubelet-<span class="hljs-number">1.17</span><span class="hljs-number">.3</span> kubeadm-<span class="hljs-number">1.17</span><span class="hljs-number">.3</span> kubectl-<span class="hljs-number">1.17</span><span class="hljs-number">.3</span> --disableexcludes=kubernetes

# 启动并设置 kubelet 开机启动
systemctl start kubelet
systemctl enable --now kubelet</code></pre>

<blockquote>
<p>⚠️⚠️⚠️WARNING</p>
<p>如果此时执行 systemctl status kubelet 命令，系统日志将得到 kubelet 启动失败的错误提示，请忽略此错误，因为必须完成后续步骤中 kubeadm init 的操作，kubelet 才能正常启动</p>
</blockquote>
<h1 id="四、使用-Kubeadm-创建集群"><a href="#四、使用-Kubeadm-创建集群" class="headerlink" title="四、使用 Kubeadm 创建集群"></a>四、使用 Kubeadm 创建集群</h1><h2 id="4-1、初始化-Control-plane-Master-节点"><a href="#4-1、初始化-Control-plane-Master-节点" class="headerlink" title="4.1、初始化 Control-plane/Master 节点"></a>4.1、初始化 Control-plane/Master 节点</h2><p>在第一台 Master 上执行初始化，执行初始化使用 kubeadm init 命令。初始化首先会执行一系列的运行前检查来确保机器满足运行 Kubernetes 的条件，这些检查会抛出警告并在发现错误的时候终止整个初始化进程。 然后 kubeadm init 会下载并安装集群的 Control-plane 组件。</p>
<p>在初始化之前，需要先设置一下 hosts 解析，为了避免可能出现的问题，后面的 Worker 节点我也进行了同样的操作。注意按照你的实际情况修改Master节点的IP，并且注意 APISERVER_NAME 的值，如果你将这个 apiserver 名称设置为别的值，下面初始化时候的 –control-plane-endpoint 的值保持一致。</p>
<blockquote>
<p>提示：为了使 Kubernetes 集群高可用，建议给集群的控制节点配置负载均衡器，如 HAproxy + Keepalived 或 Nginx，云上可以使用公有云的负载均衡器，然后在以下部分设置 MASTER_IP 和 APISERVER_NAME 为负载均衡器的地址（IP:6443） 和域名。</p>
</blockquote>
<pre><code class="hljs nginx"><span class="hljs-comment"># 设置hosts</span>
<span class="hljs-attribute">echo</span> <span class="hljs-string">"127.0.0.1 $(hostname)"</span> &gt;&gt; /etc/hosts
export MASTER_IP=<span class="hljs-number">192.168.115.49</span>
export APISERVER_NAME=kuber4s.api
echo <span class="hljs-string">"<span class="hljs-variable">$&#123;MASTER_IP&#125;</span> <span class="hljs-variable">$&#123;APISERVER_NAME&#125;</span>"</span> &gt;&gt; /etc/hosts</code></pre>

<blockquote>
<p>友情提示🙂🙂🙂：</p>
<p>截止2020年01月29日，官方文档声明了使用 kubeadm 初始化 master 时，–config 这个参数是实验性质的，所以就不用了；我们用其他参数一样可以完成 master 的初始化。</p>
</blockquote>
<pre><code class="hljs yaml"><span class="hljs-string">--config</span> <span class="hljs-string">string</span>   <span class="hljs-string">kubeadm</span> <span class="hljs-string">配置文件。</span> <span class="hljs-string">警告：配置文件的使用是试验性的。</span></code></pre>

<p>下面有不带注释的初始化命令，建议先查看带注释的每个参数对应的意义，确保与你的当前配置的环境是一致的，然后再执行初始化操作，避免踩雷。</p>
<pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 初始化 Control-plane/Master 节点</span>
kubeadm init \
    --apiserver-advertise-address 0.0.0.0 \
    # API 服务器所公布的其正在监听的 IP 地址,指定“0.0.0.0”以使用默认网络接口的地址
    # 切记只可以是内网IP，不能是外网IP，如果有多网卡，可以使用此选项指定某个网卡
    --apiserver-bind-port 6443 \
    # API 服务器绑定的端口,默认 6443
    --cert-dir /etc/kubernetes/pki \
    # 保存和存储证书的路径，默认值："/etc/kubernetes/pki"
    --control-plane-endpoint kuber4s.api \
    # 为控制平面指定一个稳定的 IP 地址或 DNS 名称,
    # 这里指定的 kuber4s.api 已经在 /etc/hosts 配置解析为本机IP
    --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers \
    # 选择用于拉取Control-plane的镜像的容器仓库，默认值："k8s.gcr.io"
    # 因 Google被墙，这里选择国内仓库
    --kubernetes-version 1.17.3 \
    # 为Control-plane选择一个特定的 Kubernetes 版本， 默认值："stable-1"
    --node-name master01 \
    #  指定节点的名称,不指定的话为主机hostname，默认可以不指定
    --pod-network-cidr 10.10.0.0/16 \
    # 指定pod的IP地址范围
    --service-cidr 10.20.0.0/16 \
    # 指定Service的VIP地址范围
    --service-dns-domain cluster.local \
    # 为Service另外指定域名，默认"cluster.local"
    --upload-certs
    # 将 Control-plane 证书上传到 kubeadm-certs Secret</code></pre>

<p>不带注释的内容如下，如果初始化超时，可以修改DNS为8.8.8.8后重启网络服务再次尝试。</p>
<pre><code class="hljs shell">kubeadm init \
 --apiserver-advertise-address 0.0.0.0 \
 --apiserver-bind-port 6443 \
 --cert-dir /etc/kubernetes/pki \
 --control-plane-endpoint kuber4s.api \
 --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers \
 --kubernetes-version 1.17.3 \
 --pod-network-cidr 10.10.0.0/16 \
 --service-cidr 10.20.0.0/16 \
 --service-dns-domain cluster.local \
 --upload-certs</code></pre>

<p>接下来这个过程有点漫长（初始化会下载镜像、创建配置文件、启动容器等操作），泡杯茶，耐心等待，你也可以执行 tailf /var/log/messages 来实时查看系统日志，观察 Master 的初始化进展，期间碰到一些报错不要紧张，可能只是暂时的错误，等待最终反馈的结果即可。</p>
<p>如果初始化最终成功执行，你将看到如下信息：</p>
<pre><code class="hljs bash">Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p <span class="hljs-variable">$HOME</span>/.kube
  sudo cp -i /etc/kubernetes/admin.conf <span class="hljs-variable">$HOME</span>/.kube/config
  sudo chown $(id -u):$(id -g) <span class="hljs-variable">$HOME</span>/.kube/config

You should now deploy a pod network to the cluster.
Run <span class="hljs-string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following <span class="hljs-built_in">command</span> on each as root:

  kubeadm join kuber4s.api:6443 --token 0j287q.jw9zfjxud8w85tis \
    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f \
    --control-plane --certificate-key 528b0b9f2861f8f02dfd4a59fc54ad21e42a7dea4dc5552ac24d9c650c5d4d80

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted <span class="hljs-keyword">in</span> two hours; If necessary, you can use
<span class="hljs-string">"kubeadm init phase upload-certs --upload-certs"</span> to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join kuber4s.api:6443 --token 0j287q.jw9zfjxud8w85tis \
    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f</code></pre>

<p>为普通用户添加 kubectl 运行权限，命令内容在初始化成功后的输出内容中可以看到。</p>
<pre><code class="hljs shell">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config</code></pre>

<p>建议root用户也进行以上操作，作者使用的是root用户执行的初始化操作，然后在操作完成后查看集群状态的时候，出现如下错误：</p>
<pre><code class="hljs shell">The connection to the server localhost:8080 was refused - did you specify the right host or port?</code></pre>

<p>这时候请备份好 kubeadm init 输出中的 kubeadm join 命令，因为将会需要这个命令来给集群添加节点。</p>
<blockquote>
<p>⚠️⚠️⚠️提示：令牌是主节点和新添加的节点之间进行相互身份验证的，因此请确保其安全。任何人只要知道了这些令牌，就可以随便给您的集群添加节点。 你可以使用 kubeadm token 命令来查看、创建和删除这类令牌。</p>
</blockquote>
<h2 id="4-2、安装-Pod-网络附加组件"><a href="#4-2、安装-Pod-网络附加组件" class="headerlink" title="4.2、安装 Pod 网络附加组件"></a>4.2、安装 Pod 网络附加组件</h2><p>关于 Kubernetes 网络，建议读完这篇 <a href="https://yuerblog.cc/2019/02/25/flannel-and-calico/" target="_blank" rel="noopener">文章</a>，以及文末的其他链接，如<a href="https://juejin.im/entry/599d33ad6fb9a0247804d430" target="_blank" rel="noopener">这个</a>。</p>
<p>集群必须安装Pod网络插件，以使Pod可以相互通信，只需要在Master节点操作，其他新加入的节点会自动创建相关pod。</p>
<p>必须在任何应用程序之前部署网络组件。另外，在安装网络之前，CoreDNS将不会启动（你可以通过命令 kubectl get pods –all-namespaces|grep coredns 查看 CoreDNS 的状态）。</p>
<pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 查看 CoreDNS 的状态,并不是 Running 状态</span>
<span class="hljs-meta">$</span><span class="bash"> kubectl get pods --all-namespaces|grep coredns</span>
kube-system   coredns-7f9c544f75-bzksd    0/1   Pending   0     14m
kube-system   coredns-7f9c544f75-mtrwq    0/1   Pending   0     14m</code></pre>

<p>kubeadm 支持多种网络插件，我们选择 Calico 网络插件（kubeadm 仅支持基于容器网络接口（CNI）的网络（不支持kubenet）。），默认情况下，它给出的pod的IP段地址是 192.168.0.0/16 ,如果你的机器已经使用了此IP段，就需要修改这个配置项，将其值改为在初始化 Master 节点时使用 kubeadm init –pod-network-cidr=x.x.x.x/x 的IP地址段，即我们上面配置的 10.10.0.0/16 ，大概在625行左右，操作如下:</p>
<pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 获取配置文件</span>
mkdir calico &amp;&amp; cd calico
wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml

<span class="hljs-meta">#</span><span class="bash"> 修改配置文件</span>
<span class="hljs-meta">#</span><span class="bash"> 找到 625 行左右的 192.168.0.0/16 ，并修改为我们初始化时配置的 10.10.0.0/16</span>
vim calico.yaml

<span class="hljs-meta">#</span><span class="bash"> 部署 Pod 网络组件</span>
kubectl apply -f calico.yaml</code></pre>

<p>稍等片刻查询 pod 详情，你也可以使用 watch 命令来实时查看 pod 的状态，等待 Pod 网络组件部署成功后，就可以看到一些信息了，包括 Pod 的 IP 地址信息，这个过程时间可能会有点长。</p>
<pre><code class="hljs shell">watch -n 2 kubectl get pods --all-namespaces -o wide</code></pre>

<h2 id="4-3、将-Worker-节点添加到-Kubernetes"><a href="#4-3、将-Worker-节点添加到-Kubernetes" class="headerlink" title="4.3、将 Worker 节点添加到 Kubernetes"></a>4.3、将 Worker 节点添加到 Kubernetes</h2><p>请首先确认 Worker 节点满足第一部分的环境说明，并且已经安装了 Docker 和 kubeadm、kubelet 、kubectl，并且已经启动 kubelet。</p>
<pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 添加 Hosts 解析</span>
echo "127.0.0.1 $(hostname)" &gt;&gt; /etc/hosts
export MASTER_IP=192.168.115.49
export APISERVER_NAME=kuber4s.api
echo "$&#123;MASTER_IP&#125; $&#123;APISERVER_NAME&#125;" &gt;&gt; /etc/hosts</code></pre>

<p>将 Worker 节点添加到集群，这里注意，执行后可能会报错，有幸的话你会跳进这个坑，这是因为 Worker 节点加入集群的命令实际上在初始化 master 时已经有提示出来了，不过两小时后会删除上传的证书，所以如果你此时加入集群的时候提示证书相关的错误，请执行 kubeadm init phase upload-certs –upload-certs 重新加载证书。</p>
<pre><code class="hljs bash">kubeadm join kuber4s.api:6443 --token 0y1dj2.ih27ainxwyib0911 \
    --discovery-token-ca-cert-hash sha256:5204b3e358a0d568e147908cba8036bdb63e604d4f4c1c3730398f33144fac61 \</code></pre>

<p>执行加入操作，你可能会发现卡着不动，大概率是因为令牌ID对此集群无效或已过 2 小时的有效期（通过执行 kubeadm join –v=5 来获取详细的加入过程，看到了内容为 ”token id “0y1dj2” is invalid for this cluster or it has expired“ 的提示），接下来需要在 Master 上通过 kubeadm token create 来创建新的令牌。</p>
<pre><code class="hljs sh">$ kubeadm token create --<span class="hljs-built_in">print</span>-join-command
W0129 19:10:04.842735   15533 validation.go:28] Cannot validate kube-proxy config - no validator is available
W0129 19:10:04.842808   15533 validation.go:28] Cannot validate kubelet config - no validator is available
<span class="hljs-comment"># 输出结果如下</span>
kubeadm join kuber4s.api:6443 --token 1hk9bc.oz7f3lmtbzf15x9b     --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f</code></pre>

<p>在 Worker 节点上重新执行加入集群命令</p>
<pre><code class="hljs shell">kubeadm join kuber4s.api:6443 \
    --token 1hk9bc.oz7f3lmtbzf15x9b \
    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f</code></pre>

<p>接下来在Master上查看 Worker 节点加入的状况，直到 Worker 节点的状态变为 Ready 便证明加入成功，这个过程可能会有点漫长，30 分钟以内都算正常的，主要看你网络的情况或者说拉取镜像的速度；另外不要一看到 /var/log/messages 里面报错就慌了，那也得看具体报什么错，看不懂就稍微等一下，一般在 Master 上能看到已经加入（虽然没有Ready）就没什么问题。</p>
<pre><code class="hljs shell">watch kubectl get nodes -o wide</code></pre>

<h2 id="4-4、添加-Master-节点"><a href="#4-4、添加-Master-节点" class="headerlink" title="4.4、添加 Master 节点"></a>4.4、添加 Master 节点</h2><p>需要至少2个CPU核心，否则会报错</p>
<pre><code class="hljs shell">kubeadm join kuber4s.api:6443 \
    --token 1hk9bc.oz7f3lmtbzf15x9b \
    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f \
    --control-plane --certificate-key 5253fc7e9a4e6204d0683ed2d60db336b3ff64ddad30ba59b4c0bf40d8ccadcd</code></pre>

<h2 id="4-5、补充内容"><a href="#4-5、补充内容" class="headerlink" title="4.5、补充内容"></a>4.5、补充内容</h2><ul>
<li><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/" target="_blank" rel="noopener">kubeadm init</a> 初始化 Kubernetes 主节点</li>
<li><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/" target="_blank" rel="noopener">kubeadm token</a> 管理 kubeadm join 的令牌</li>
<li><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-reset/" target="_blank" rel="noopener">kubeadm reset</a> 将 kubeadm init 或 kubeadm join 对主机的更改恢复到之前状态，一般与 -f 参数使用</li>
</ul>
<p>移除 worker 节点</p>
<p>正常情况下，你无需移除 worker 节点，如果要移除，在准备移除的 worker 节点上执行</p>
<pre><code class="hljs shell">kubeadm reset -f</code></pre>

<p>或者在 Control-plane 上执行</p>
<pre><code class="hljs shell">kubectl delete node nodename</code></pre>

<blockquote>
<ul>
<li>将 nodename 替换为要移除的 worker 节点的名字</li>
<li>worker 节点的名字可以通过在 Control-plane 上执行 kubectl get nodes 命令获得</li>
</ul>
</blockquote>
<h1 id="五、Kubernetes-高可用集群"><a href="#五、Kubernetes-高可用集群" class="headerlink" title="五、Kubernetes 高可用集群"></a>五、Kubernetes 高可用集群</h1><h2 id="5-1、环境说明"><a href="#5-1、环境说明" class="headerlink" title="5.1、环境说明"></a>5.1、环境说明</h2><p>如果你使用的是以上方法部署你的 Kubernetes 集群，想在当前基础上进行高可用集群的创建，则可以按照下面的步骤继续进行。</p>
<p>值得注意的是，这里没有将ETCD放在Master外的机器上，而是使用默认的架构，即官方的 Stacked etcd topology 方式的集群</p>
<p><img src="D:%5CBlog%5Cyyuangeek.github.io%5Csource_posts%5C%E6%89%8B%E6%8A%8A%E6%89%8B%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E4%B8%8E%E8%BF%90%E8%90%A5%E7%94%9F%E4%BA%A7%E7%BA%A7%E7%9A%84-Kubernetes-%E9%9B%86%E7%BE%A4%E4%B8%8E-KubeSphere%5C2020-03-25-091655.png" srcset="/img/loading.gif" alt="2020-03-25-091655"></p>
<p>你需要至少 3 台 Master 节点和 3 台 Worker 节点，或者更多的机器，但要保证是 Master 和 Worker 节点数都是奇数的，以防止 leader 选举时出现脑裂状况。</p>
<table>
<thead>
<tr>
<th align="center">机器名称</th>
<th align="center">机器IP</th>
<th align="center">工作内容</th>
</tr>
</thead>
<tbody><tr>
<td align="center">master01</td>
<td align="center">192.168.115.49</td>
<td align="center">master、etcd</td>
</tr>
<tr>
<td align="center">master02</td>
<td align="center">192.168.115.41</td>
<td align="center">master、etcd</td>
</tr>
<tr>
<td align="center">master03</td>
<td align="center">192.168.115.42</td>
<td align="center">master、etcd</td>
</tr>
<tr>
<td align="center">node01</td>
<td align="center">192.168.115.46</td>
<td align="center">worker</td>
</tr>
<tr>
<td align="center">node02</td>
<td align="center">192.168.115.47</td>
<td align="center">worker</td>
</tr>
<tr>
<td align="center">node03</td>
<td align="center">192.168.115.48</td>
<td align="center">worker</td>
</tr>
<tr>
<td align="center">nfs</td>
<td align="center">192.168.115.50</td>
<td align="center">存储</td>
</tr>
</tbody></table>
<h2 id="5-2、高可用扩展"><a href="#5-2、高可用扩展" class="headerlink" title="5.2、高可用扩展"></a>5.2、高可用扩展</h2><p>Kubernetes 的高可用扩展其实挺简单，你只需要将不同的 Master 和 Worker 节点加入到集群中就行了。加入的指令在你初始化集群时已经给出了。</p>
<ul>
<li>添加 Master 节点：</li>
</ul>
<p>需要至少 2 个 CPU 核心，否则会报错</p>
<pre><code class="hljs bash">kubeadm join kuber4s.api:6443 \
 --token 1hk9bc.oz7f3lmtbzf15x9b \
 --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f \
 --control-plane --certificate-key 5253fc7e9a4e6204d0683ed2d60db336b3ff64ddad30ba59b4c0bf40d8ccadcd</code></pre>

<ul>
<li>添加 Worker 节点</li>
</ul>
<p>在 Worker 节点上重新执行加入集群命令</p>
<pre><code class="hljs bash">kubeadm join kuber4s.api:6443 \
--token 1hk9bc.oz7f3lmtbzf15x9b \
--discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f</code></pre>

<h1 id="六、安装-KubeSphere"><a href="#六、安装-KubeSphere" class="headerlink" title="六、安装 KubeSphere"></a>六、安装 KubeSphere</h1><h2 id="6-1、KubeSphere简介"><a href="#6-1、KubeSphere简介" class="headerlink" title="6.1、KubeSphere简介"></a>6.1、KubeSphere简介</h2><p>Kubernetes 官方有提供一套 Dashboard，但是我这里选择功能更强大的 KubeSphere，以下内容引用自 KubeSphere 官网：</p>
<p><a href="https://kubesphere.com.cn/docs/zh-CN/" target="_blank" rel="noopener">KubeSphere</a> 是在 <a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a> 之上构建的以应用为中心的容器平台，提供简单易用的操作界面以及向导式操作方式，在降低用户使用容器调度平台学习成本的同时，极大减轻开发、测试、运维的日常工作的复杂度，旨在解决 Kubernetes 本身存在的存储、网络、安全和易用性等痛点。除此之外，平台已经整合并优化了多个适用于容器场景的功能模块，以完整的解决方案帮助企业轻松应对敏捷开发与自动化运维、DevOps、微服务治理、灰度发布、多租户管理、工作负载和集群管理、监控告警、日志查询与收集、服务与网络、应用商店、镜像构建与镜像仓库管理和存储管理等多种场景。后续版本将提供和支持多集群管理、大数据、AI 等场景。</p>
<p><img src="D:%5CBlog%5Cyyuangeek.github.io%5Csource_posts%5C%E6%89%8B%E6%8A%8A%E6%89%8B%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E4%B8%8E%E8%BF%90%E8%90%A5%E7%94%9F%E4%BA%A7%E7%BA%A7%E7%9A%84-Kubernetes-%E9%9B%86%E7%BE%A4%E4%B8%8E-KubeSphere%5C20200327114511.png" srcset="/img/loading.gif" alt="20200327114511"></p>
<h2 id="6-2、安装要求"><a href="#6-2、安装要求" class="headerlink" title="6.2、安装要求"></a>6.2、安装要求</h2><p>KubeSphere 支持直接在 Linux 上部署集群，也支持在 Kubernetes 上部署，我这里选择后者，基本的要求如下：</p>
<ul>
<li>Kubernetes 版本：1.15.x ≤ K8s version ≤ 1.17.x；</li>
<li>Helm 版本：2.10.0 ≤ Helm Version ＜ 3.0.0（不支持 helm 2.16.0<a href="https://github.com/helm/helm/issues/6894" target="_blank" rel="noopener">#6894</a>），且已安装了 Tiller，参考 <a href="https://devopscube.com/install-configure-helm-kubernetes/" target="_blank" rel="noopener">如何安装与配置 Helm</a>（预计 3.0 支持 Helm v3）；</li>
<li>集群已有默认的存储类型（StorageClass），若还没有准备存储请参考<a href="https://kubesphere.com.cn/docs/zh-CN/appendix/install-openebs" target="_blank" rel="noopener">安装 OpenEBS 创建 LocalPV 存储类型</a>用作开发测试环境。</li>
<li>集群能够访问外网，若无外网请参考 <a href="https://kubesphere.com.cn/docs/installation/install-on-k8s-airgapped/" target="_blank" rel="noopener">在 Kubernetes 离线安装 KubeSphere</a>。</li>
</ul>
<h2 id="6-3、安装-Helm"><a href="#6-3、安装-Helm" class="headerlink" title="6.3、安装 Helm"></a>6.3、安装 Helm</h2><h3 id="6-3-1、Helm-简介"><a href="#6-3-1、Helm-简介" class="headerlink" title="6.3.1、Helm 简介"></a>6.3.1、Helm 简介</h3><p>Helm 基本思想如图所示</p>
<p><img src="D:%5CBlog%5Cyyuangeek.github.io%5Csource_posts%5C%E6%89%8B%E6%8A%8A%E6%89%8B%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E4%B8%8E%E8%BF%90%E8%90%A5%E7%94%9F%E4%BA%A7%E7%BA%A7%E7%9A%84-Kubernetes-%E9%9B%86%E7%BE%A4%E4%B8%8E-KubeSphere%5C2020-03-25-095440.png" srcset="/img/loading.gif" alt="2020-03-25-095440"></p>
<p>以下内容引用自 <a href="https://blog.csdn.net/weixin_30566063/article/details/99247145" target="_blank" rel="noopener">此篇文章</a></p>
<p>Helm 基本概念</p>
<p>Helm 可以理解为 Kubernetes 的包管理工具，可以方便地发现、共享和使用为Kubernetes构建的应用，它包含几个基本概念：</p>
<ul>
<li>Chart：一个 Helm 包，其中包含了运行一个应用所需要的镜像、依赖和资源定义等，还可能包含 Kubernetes 集群中的服务定义</li>
<li>Release: 在 Kubernetes 集群上运行的 Chart 的一个实例。在同一个集群上，一个 Chart 可以安装很多次。每次安装都会创建一个新的 release。例如一个 MySQL Chart，如果想在服务器上运行两个数据库，就可以把这个 Chart 安装两次。每次安装都会生成自己的 Release，会有自己的 Release 名称。</li>
<li>Repository：用于发布和存储 Chart 的仓库。</li>
</ul>
<h3 id="6-3-2、Helm安装"><a href="#6-3-2、Helm安装" class="headerlink" title="6.3.2、Helm安装"></a>6.3.2、Helm安装</h3><p>安装过程如下</p>
<pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 创建部署目录并下载Helm</span>
mkdir tiller
cd tiller

<span class="hljs-meta">#</span><span class="bash"> 先使用官方的方式安装，如果安装不了，可以看到下载文件的地址，然后手动下载解压</span>
curl -L https://git.io/get_helm.sh | bash
<span class="hljs-meta">#</span><span class="bash"> 获取到下载地址后，想办法下载</span>
wget https://get.helm.sh/helm-v2.16.3-linux-amd64.tar.gz
tar zxf helm-v2.16.3-linux-amd64.tar.gz
mv linux-amd64/helm /usr/local/bin/helm

<span class="hljs-meta">#</span><span class="bash"> 验证</span>
helm version</code></pre>

<p>部署 Tiller，即 Helm 的服务端。先创建 SA</p>
<pre><code class="hljs yaml"><span class="hljs-comment"># yaml文件如下</span>
<span class="hljs-string">$</span> <span class="hljs-string">cat</span> <span class="hljs-string">/root/tiller/helm-rbac.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span>
<span class="hljs-attr">metadata:</span>
 <span class="hljs-attr">name:</span> <span class="hljs-string">tiller</span>
 <span class="hljs-attr">namespace:</span> <span class="hljs-string">kube-system</span>
<span class="hljs-meta">---</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRoleBinding</span>
<span class="hljs-attr">metadata:</span>
 <span class="hljs-attr">name:</span> <span class="hljs-string">tiller</span>
<span class="hljs-attr">roleRef:</span>
 <span class="hljs-attr">apiGroup:</span> <span class="hljs-string">rbac.authorization.k8s.io</span>
 <span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span>
 <span class="hljs-attr">name:</span> <span class="hljs-string">cluster-admin</span>
<span class="hljs-attr">subjects:</span>
 <span class="hljs-bullet">-</span> <span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span>
 <span class="hljs-attr">name:</span> <span class="hljs-string">tiller</span>
 <span class="hljs-attr">namespace:</span> <span class="hljs-string">kube-system</span></code></pre>

<p>创建 RBAC：</p>
<pre><code class="hljs shell">kubectl apply -f helm-rbac.yaml</code></pre>

<p>初始化，这个过程可能不会成功，具体接着往下看</p>
<pre><code class="hljs shell">helm init --service-account=tiller --history-max 300</code></pre>

<p>检查初始化的情况，不出意外的话，墙内用户看pod详情可以看到获取不到镜像的错误。</p>
<pre><code class="hljs shell">kubectl get deployment tiller-deploy -n kube-system</code></pre>

<p>如果一直获取不到镜像，可以通过更换到Azure中国镜像源来解决，操作步骤如下：</p>
<pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 编辑 deploy</span>
kubectl edit deploy tiller-deploy -n kube-system
<span class="hljs-meta">#</span><span class="bash"> 查找到image地址，替换为如下地址，保存退出</span>
gcr.azk8s.cn/kubernetes-helm/tiller:v2.16.3</code></pre>

<p>接下来稍等片刻，再次查看deployment和pod详情，就正常了</p>
<pre><code class="hljs shell">kubectl get deployment tiller-deploy -n kube-system</code></pre>

<h2 id="6-4、安装-StorageClass"><a href="#6-4、安装-StorageClass" class="headerlink" title="6.4、安装 StorageClass"></a>6.4、安装 StorageClass</h2><p>Kubernetes 支持多种 StorageClass，我这选择 NFS 作为集群的 StorageClass。</p>
<p>参考地址：<a href="https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client</a></p>
<h3 id="6-4-1、下载所需文件"><a href="#6-4-1、下载所需文件" class="headerlink" title="6.4.1、下载所需文件"></a>6.4.1、下载所需文件</h3><p>下载所需文件，并进行内容调整</p>
<pre><code class="hljs shell">mkdir nfsvolume &amp;&amp; cd nfsvolume
for file in class.yaml deployment.yaml rbac.yaml ; do wget https://raw.githubusercontent.com/kubernetes-incubator/external-storage/master/nfs-client/deploy/$file ; done</code></pre>

<p>修改 deployment.yaml 中的两处 NFS 服务器 IP 和目录</p>
<pre><code class="hljs yaml"><span class="hljs-string">...</span>
          <span class="hljs-attr">env:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">PROVISIONER_NAME</span>
              <span class="hljs-attr">value:</span> <span class="hljs-string">fuseim.pri/ifs</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">NFS_SERVER</span>
              <span class="hljs-attr">value:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.115</span><span class="hljs-number">.50</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">NFS_PATH</span>
              <span class="hljs-attr">value:</span> <span class="hljs-string">/data/k8s</span>
      <span class="hljs-attr">volumes:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nfs-client-root</span>
          <span class="hljs-attr">nfs:</span>
            <span class="hljs-attr">server:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.115</span><span class="hljs-number">.50</span>
            <span class="hljs-attr">path:</span> <span class="hljs-string">/data/k8s</span></code></pre>

<h2 id="6-4-2、部署创建"><a href="#6-4-2、部署创建" class="headerlink" title="6.4.2、部署创建"></a>6.4.2、部署创建</h2><p>具体的说明可以去官网查看。</p>
<pre><code class="hljs shell">kubectl create -f rbac.yaml
kubectl create -f class.yaml
kubectl create -f deployment.yaml</code></pre>

<p>如果日志中看到“上有坏超级块”，请在集群内所有机器上安装nfs-utils并启动。</p>
<pre><code class="hljs shell">yum -y install nfs-utils
systemctl start nfs-utils
systemctl enable nfs-utils
rpcinfo -p</code></pre>

<p>查看storageclass</p>
<pre><code class="hljs java">$ kubectl get storageclass
NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE
managed-nfs-storage fuseim.pri/ifs Delete Immediate <span class="hljs-keyword">false</span> <span class="hljs-number">10</span>m</code></pre>

<h3 id="6-4-3、标记一个默认的-StorageClass"><a href="#6-4-3、标记一个默认的-StorageClass" class="headerlink" title="6.4.3、标记一个默认的 StorageClass"></a>6.4.3、标记一个默认的 StorageClass</h3><p>操作命令格式如下</p>
<pre><code class="hljs shell">kubectl patch storageclass  -p '&#123;"metadata": &#123;"annotations":&#123;"storageclass.kubernetes.io/is-default-class":"true"&#125;&#125;&#125;'</code></pre>

<p>请注意，最多只能有一个 StorageClass 能够被标记为默认。</p>
<p>验证标记是否成功</p>
<pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> kubectl get storageclass</span>
NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE
managed-nfs-storage (default) fuseim.pri/ifs Delete Immediate false 12m</code></pre>

<h2 id="6-5、部署-KubeSphere"><a href="#6-5、部署-KubeSphere" class="headerlink" title="6.5、部署 KubeSphere"></a>6.5、部署 KubeSphere</h2><p>过程很简单，如果你的机器资源足够，建议你进行完整安装，操作步骤如下。如果你的资源不是很充足，则可以进行最小化安装，<a href="https://kubesphere.com.cn/docs/zh-CN/installation/prerequisites/" target="_blank" rel="noopener">参考地址</a>。我当然是选择完整安装了，香！</p>
<pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 下载 yaml 文件</span>
mkdir kubesphere &amp;&amp; cd kubesphere
wget https://raw.githubusercontent.com/kubesphere/ks-installer/master/kubesphere-complete-setup.yaml
<span class="hljs-meta">#</span><span class="bash"> 部署 KubeSphere</span>
kubectl apply -f kubesphere-complete-setup.yaml</code></pre>

<p>这个过程根据你实际网速，实际使用时间长度有所不同。你可以通过如下命令查看实时的日志输出。</p>
<pre><code class="hljs shell">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath='&#123;.items[0].metadata.name&#125;') -f</code></pre>

<p>当你看到如下日志输出，证明你的 KubeSphere 部署成功</p>
<pre><code class="hljs bash">**************************************************
task monitoring status is successful
task notification status is successful
task devops status is successful
task alerting status is successful
task logging status is successful
task openpitrix status is successful
task servicemesh status is successful
total: 7     completed:7
**************************************************
<span class="hljs-comment">#####################################################</span>
<span class="hljs-comment">###              Welcome to KubeSphere!           ###</span>
<span class="hljs-comment">#####################################################</span>

Console: http://192.168.115.49:30880
Account: admin
Password: P@88w0rd
<span class="hljs-comment">#####################################################</span></code></pre>

<p>确认 Pod 都正常运行后，可使用IP:30880访问 KubeSphere UI 界面，默认的集群管理员账号为admin/P@88w0rd，Enjoy it，😏！</p>
<p><img src="D:%5CBlog%5Cyyuangeek.github.io%5Csource_posts%5C%E6%89%8B%E6%8A%8A%E6%89%8B%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E4%B8%8E%E8%BF%90%E8%90%A5%E7%94%9F%E4%BA%A7%E7%BA%A7%E7%9A%84-Kubernetes-%E9%9B%86%E7%BE%A4%E4%B8%8E-KubeSphere%5C2020-03-25-103029.png" srcset="/img/loading.gif" alt="2020-03-25-103029"></p>
<p><img src="D:%5CBlog%5Cyyuangeek.github.io%5Csource_posts%5C%E6%89%8B%E6%8A%8A%E6%89%8B%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E4%B8%8E%E8%BF%90%E8%90%A5%E7%94%9F%E4%BA%A7%E7%BA%A7%E7%9A%84-Kubernetes-%E9%9B%86%E7%BE%A4%E4%B8%8E-KubeSphere%5C2020-03-25-145648.png" srcset="/img/loading.gif" alt="2020-03-25-145648"></p>
<p>作者：KubeSphere</p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/k8s-cloudnative-docker/">k8s,cloudnative,docker</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/05/28/%E4%BD%BF%E7%94%A8Spring-Boot-Operator%E9%83%A8%E7%BD%B2SpringBoot%E5%88%B0K8S/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">使用Spring Boot Operator部署SpringBoot到K8S</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/05/28/%E5%9C%A8Kubernetes%E4%B8%8A%E9%83%A8%E7%BD%B2Elasticsearch%E9%9B%86%E7%BE%A4/">
                        <span class="hidden-mobile">在Kubernetes上部署Elasticsearch集群</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://www.sciencemag.org/" target="_blank" rel="nofollow noopener"><span>Science</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/yyuangeek" target="_blank" rel="nofollow noopener">
        <span>YYUAN</span></a>
    </div>
    

    
  <!-- 备案信息 -->
  <div class="beian">
    <a href="http://beian.miit.gov.cn/" target="_blank"
       rel="nofollow noopener">京ICP备20021675号</a>
    
      <a
        href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=12345678"
        rel="nofollow noopener"
        class="beian-police"
        target="_blank"
      >
        <span class="beian-police-sep">&nbsp;|&nbsp;</span>
        
          <img src="/img/police_beian.png" srcset="/img/loading.gif" alt="police-icon" />
        
        <span>京公网安备12345678号</span>
      </a>
     
  </div>


    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "手把手从零搭建与运营生产级的 Kubernetes 集群与 KubeSphere&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>




















</body>
</html>
